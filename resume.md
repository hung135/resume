# Hung Nguyen

## Experience Summary

Experienced Enterprise Data Architect with over 28 years of expertise in Data Management, Cloud, and Automation. A proven track record of supporting various government clients, leveraging breadth of knowledge and proficiency to help clients devise solutions to their mission-critical systems. Remains very hands-on and actively involved in projects to provide valuable insights and contribute to the success of the team. 

## Education

**Bachelor of Science** in Computer Science from James Madison University, 1999

## CERTIFICATIONS AND TRAINING
- AWS Solutions Architect Associate Certified (10/2018)
- Certified Scrum Master Training (2015, 2017)

## KEY SKILLS AREAS
- Programming Proficiency in Most Languages
- Information Systems Engineering & Integration
- Breadth of knowledge across various IT disciplines
- Process & Product Development
- Automation and Continuous Delivery
- Performance Tuning

## EXPERIENCE
**GreenZone Solutions Inc.**\
_Data Architect - Consultant_\
Arlington, VA\
1/2017
- Establish automation and development standards for Chief Data Office engineers.
- Design Continuous delivery data pipelines to move data between federated data sources
- Created data migration framework to facilitate data ingestion, ETL, and deployment
- Designed Normal Form Relational Model CFPB Chief Data Office’s Data Warehouse
- Revised and optimized problem processes to effectively utilize processing power across distributed Mesos worker agents
- Implemented data sharding strategy to house Big Relational Data in CitusDB, AWS Redshift, and AWS RDS
- Provided DataMart catered to various Financial and Economic Research groups
- Devised data migration strategy from local datacenter to AWS cloud native infrastructure
- Utilized Python and Airflow to build data pipelines and move data to Snowflake, enabling efficient and streamlined data management and analysis.
- Leveraged all prominent AWS Lambda, S3, SNS, ECS, Glue, RDS, Redshift and other various other services to replace legacy big data system
- Leverage Vagrant, Docker to facilitate productivity for fellow team members.
- Used various programming (Python, Java, Go, Bash) languages to quickly devise solutions for each use case
- Leverage GIT configuration management services to integrate Continuous delivery and Continuous integration pipelines.
- Created custom parallel processing pipelines to move data faster between systems than any available COTS product
 
**Taurus Telesys (2011 - 2019)**\
_Expert Consultant (Part-time)_\
*Subcontractor supporting the New Port News Ship Building in data management for the systems testing platform, with focus on embedded equipment including valves and sensors. Responsible for managing PLCs, including Allen Bradley. The testing platform was created using virtualization to simulate every component on the Nuclear Carrier. Setup of hardware, network, and software was done in a classified facility. Containerized workloads and ran CI/CD to test delivered code. Built and offered solutions such as NetA/NetB and VRRP that worked on packet level delivery of data.*

- Oversaw and managed data management for the embedded equipment including valves and sensors, as well as PLCs including Allen Bradley, needed to produce the systems testing platform
- Developed and implemented data management processes to improve efficiency and productivity
- Devised and organized all requirements and infrastructure to implement CI/CD in an air-gapped environment
- Collaborated with cross-functional teams to identify and prioritize data needs for the embedded equipment, PLCs, virtualization technology, containerization, CI/CD, and packet level data delivery solutions such as NetA/NetB and VRRP
- Analyzed data trends and patterns for the embedded equipment, PLCs, virtualization technology, containerization, CI/CD, and packet level data delivery solutions to identify opportunities for process improvement
- Trained and mentored junior data management staff


**NCMEC**\
_Data Solutions Architect - Consultant_\
Alexandria, VA\
9/2011
- Contributed to over 60 projects during his time at NCMEC.
- Hands on in virtually every aspect of NCMEC’s software architecture which incorporates partnering with all major IT services companies.
- Designed, wrote and maintained Erwin data model, scripts, DDL, DML for all NCMEC databases.
- Scripted and devised Database backup scheme to backup mission critical database daily.
- Used CVS, SVN and GIT to version control all scripts, stored procedure and code.
- Devised process to automate Tag deployment through development and production tiers.
- Orchestrated development and design of enterprise MYSQL RDMS, NoSQL and Search indexing technologies.
- Set up pipelines to feed data into Elastic search and configured and optimized the Elastic search implementation to index and search for missing children metadata
- Implement Docker, Docker swarm and created Docker build scripts to replace VM environments
- Identified and engineer systems level micro services to evolve NCMEC’s Enterprise Architecture
- Engaged end user and encourage discussion to extrapolate and clarify requirements
- Engineered and continually evolve a Cartesian BIG DATA solution to identify child porn worldwide. 
- Wrote NVidia CUDA, C++ to exploit 1000’s of Cores provided by GPU
- Implemented MapReduce Using Hadoop: v2.0
- Worked with Java core to develop stand-alone java process for PDNA
- Created early protoypes Docker Swarm + Micro Services + Go Lang


**Northrup Grumman**\
_Data Architect - Consultant_\
Sykesville, MD\
7/2007
- Instituted industries best practices to MYSQL RDBMS approach to systems design and implementation. Responsible for all designing, creation and changes to MYSL RDMS.
- Devised systematic approach to implementation of large scale distributed information systems with complex interconnectivity and algorithm processing.
- Established IDD (Interface Design Definitions) for 12 Federated Information Systems Programs.
- Assisted in the hardware/software/network architectural design and review.  Applied analytical skills to assist in derivation of requirements and systems knowledge to usable and implementation information.
- Acted as the bridge between systems (functional) engineers and software engineers via definition of systems level requirements to software requirements
- Developed complete suite of tools and processes to promote efficiency and reduce human errors. 
- Automation of Layer 3 Network Configurations using relational data modeling
- Automation of Traceability of raw Requirements to Data level and Source Code implementation
- Automation of Enterprise wide information cross reference,  enabling accountability and traceability from high level requirements to implementation details.
- Automation of Source Code generation and configuration using RDBMS models. 
- Created stand alone, client-server and web portal tools to collect/report metrics, facilitate development, integration, test and deployment of data and software using OO Socket Programming, C++, Java, MYSQL, ACCESS, DOS, Apache, PHP and various other technologies
 

### Flatter & Associates
*Full Stack Application Developer*, Northern VA, 1/2003 

**NAVAIR, Patuxent River:**

- Led development team to develop Enterprise Web-workforce shaping application to manage Navy staffing & work requirements.
- Served as lead DBA for SQL Server database and led team on front end ColdFusion MX development.
- Interfaced with Infomatica Data Warehouse to supply Navy Admirals with real-time, high integrity reports.

**NCIS, Washing Navy Yard:**

- Maintained and developed "Navy Security Net" WEB Portal, a ColdFusion MX/ Oracle backend database, to facilitate daily tasks for Navy Law Enforcement personnel.
- Wrote shell scripts to automate backup/restore procedures calling various features of Oracle including RMAN, IMP, and EXP.
- Used various tools like Erwin, Access, and Oracle Migration Workbench.
- Designed several classified web-enabled applications to aid in Vulnerability Assessment of Navy Installations and Ships worldwide, using SQL Server backend.

**USMC:**

- Developed a Marine Corps' Consolidated Law Enforcement Operations system (CLEOC) used to track Criminal activities at Marine and Navy installations worldwide using Oracle 9ias Portal and PL-SQL.
- Devised and implemented LDAP-based single sign-on from ColdFusion applications to CLEOC and other Oracle 9ias Portal apps.

**TSA, Pentagon City:**

- Designed and developed ColdFusion MX Application with Oracle 9i to Manage Vulnerability Assessments for TSA port facilities.
- The application feeds TSA's Oracle 9i Data Warehouse.

### Answerthink Inc
*Data Consultant*, Miami, FL, 9/2000 

- Led a team of programmers to develop an application at Waste Management that integrated data from various software systems, including Oracle and PeopleSoft, to determine the financial status of WMI's employees.
- Performed DBA duties using SQL-Plus, IMP, EXP, RMAN, and SQL-Loader.
- Tested the Workscape HRMS platform at BASF, developing custom test scripts using WinRunner's TSL scripting language, and analyzing various scenarios to validate Workscape's functionality against design specifications.
- Successfully brought the Benefit System Live at REVLON using ConcurHR, configuring packages, and developing customizations using Concur's development model.
- Programmed ConcurHR documents in Seeker, HTML, JavaScript, and SQL, and modified the underlying database structure as appropriate.
- Integrated Epicentric Web Portal with ConcurHR and Financial for Corporate HR.
- Experienced with software development methodologies, database management, testing, and implementation.

### Booz Allen Hamilton
*Application Developer*, Mclean, VA, 5/1999 

- Developed database management and application development using Sybase and PowerBuilder 6.0.
- Proficient in C++ for object-oriented programming and software application development.
- Developed web applications using Silverstream 3.0 and integrated JReport, a J2EE compliant reporting and graphing tool, into the Silverstream App Server.
- Developed enterprise-level software applications using JAVA 2 & MQ series US Customs workflow system.
- Experienced in developing various web and standalone applications using ColdFusion, ASP, Oracle, Sybase, Visual Basic, and Access.
- Proficient in Linux administration and wrote BASH scripts for automating tasks.
- Collaborated with development team to optimize software development processes and meet project deadlines.
- Strong problem-solving skills and ability to work under pressure.
- Excellent communication skills, both written and verbal, with ability to explain complex technical concepts to non-technical stakeholders.

### James Madison University
*JuniorETL Developer*, Harrisonburg, VA, 5/1998 

- Assisted in the migration of an ETL system from Mainframe to PeopleSoft and Oracle databases, working under the guidance of senior team members.
- Contributed to the writing of code in PL-SQL, SQR, Cobol, and PeopleCode to support the migration and integration of data.
- Supported the development of a periodic data delivery pipeline to integrate data into the PeopleSoft database.
- Assisted in the development of stored procedures and functions using PL-SQL to enhance database performance and efficiency.
- Contributed to the creation of reports using SQR to present data to end-users in a user-friendly format.
- Conducted testing and debugging of ETL processes and code to ensure data accuracy and integrity.
- Collaborated with cross-functional teams to understand business requirements and provide technical solutions.
- Provided support to end-users on the PeopleSoft system and ETL processes.
- Participated in code reviews and contributed to the development of best practices for ETL development.
